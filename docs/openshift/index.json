[
{
	"uri": "/openshift/install/arch_intro/",
	"title": "架构介绍",
	"tags": [],
	"description": "",
	"content": "    版本 日期 状态 修订人 摘要     V1.0 2018-04-17 创建 开源方案 初始版本    Openshift Origin v3.6 架构图 OpenShift 是一款容器应用平台，它将 Docker 和 Kubernetes 技术带入企业。\n上图是openshift origin 总体架构图\n上图是 openshift 和 k8s 所在容器云平台的关系\n主服务和计算节点关系结构 主服务器(Masters)依赖于基于etcd的分布式目录， 主要用来提供配置共享和服务发现\n计算节点(Nodes) 主要用来作为PODS的宿主和运行容器\n整体应用概念介绍 上述应用架构图中， 概念来源于Kubernetes的概念， 需要明白以下主要的对象。\n 一个 POD 是一个Docker 容器的运行环境(如果需要共享本地的资源， 我们将在单独的POD中布署两种类别的容器) 一个 Service 服务是一个入口(VIP)，抽象出一个均衡访问负载到一组相同的容器，理论上， 最少是一个服务对应一个架构层 一个服务布署者(Service Deployer)或布署配置(Deployment Config)是一个对象， 用来描述基于触发器的容器的布署策略(比如，当docker仓库中有新版本的映象时， 重新布署) 一个复制控制器(Replication Controller)是一个技术组件， 主要负责POD 的弹性。 一个路由(Route)是用来暴露一个应用的入口(域名解析， 主机名或VIP)  "
},
{
	"uri": "/openshift/install/env_intro/",
	"title": "部署环境介绍",
	"tags": [],
	"description": "",
	"content": "    版本 日期 状态 修订人 摘要     V1.0 2018-04-17 创建 开源方案 初始版本    Openshift v3.6 高可用部署架构图  Masters Node 负载均衡使用 HAPROXY 做基于tcp模式的负载(SSL证书穿透) Data Store 是使用etcd作为信息的存储数据库 Infrastructure Node 基础设施节点,用于运行平台自身的管理服务(route,docker仓库,度量数据,日志数据等),也可以定义一些其他功能节点 比如ops Node 主要运维相关的服务(zabbix,cmdb,ticket等),dev Node 主要运行研发相关服务(maven镜像库,gitlab,go-cd等) Persistent Storage 持久卷这里使用的是 CEPH https://ceph.com/ 分布式文件系统 操作系统发行版本使用的是 CENTOS 7  部署主机角色说明    主机角色 IP地址 操作系统 摘要 域名     管理节点(Master) openshift-master1(192.168.124.22) CentOS Linux release 7.3.1611 (Core) x86_64 master + etcd + haproxy openshift.ops.com   管理节点(Master) openshift-master2(192.168.124.23) CentOS Linux release 7.3.1611 (Core) x86_64 master + etcd openshift.ops.com   管理节点(Master) openshift-master3(192.168.124.24) CentOS Linux release 7.3.1611 (Core) x86_64 master + etcd openshift.ops.com   基础设施节点(Node) openshift-node1（192.168.124.30） CentOS Linux release 7.3.1611 (Core) X86-64 router + registry lb.openshift.ops.com   计算节点(Node) openshift-node2（192.168.124.46） CentOS Linux release 7.3.1611 (Core) X86-64 计算节点 无对外域名    注：本环境中 master节点的负载均衡haproxy 示例没有配置2个节点,如需要,可以参考互联网上 haproxy + keeplived 方式实现\n域名设置说明    域名角色 通配域名(泛域名) CNAME地址     开发环境域名 *.dev.openshift.ops.com lb.openshift.ops.com   测试环境域名 *.test.openshift.ops.com lb.openshift.ops.com   生产环境域名 *.prod.openshift.ops.com lb.openshift.ops.com    注：这里为每个环境都配置范域名解析,都指向 router 所在的计算节点上,如果没有配置DNS,做hosts绑定域名也可以\n但是 master的高可用负载域名 openshift.ops.com(指向haproxy) 在master节点所配置的dns必须能够解析,hosts绑定是无效的, 原因是计算节点运行的容器内部 /etc/resolve.conf dns是指向master节点的,如果容器内需要访问 openshift.ops.com 这个域名就会forward 主服务节点配置的dns上\n "
},
{
	"uri": "/openshift/install/etcd_install/",
	"title": "Etcd集群安装",
	"tags": [],
	"description": "",
	"content": "    版本 日期 状态 修订人 摘要     V1.0 2018-04-17 创建 开源方案 初始版本    ETCD证书  etcd集群信息     主机名 IP地址 域名 etcd版本     etcd0 192.168.124.22 etcd0.51know.info etcd-3.2.15-1.el7.x86_64   etcd1 192.168.124.23 etcd1.51know.info etcd-3.2.15-1.el7.x86_64   etcd2 192.168.124.24 etcd0.51know.info etcd-3.2.15-1.el7.x86_64     证书生成     证书名称 配置文件 用途     etcd-root-ca.pem etcd-root-ca-csr.json etcd 根 CA 证书   etcd.pem etcd-gencert.json、etcd-csr.json etcd 集群证书     CFSSL 工具安装 首先下载 cfssl，并给予可执行权限，然后扔到 PATH 目录下  [root@openshift-master1 /opt]# wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 [root@openshift-master1 /opt]# wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 [root@openshift-master1 /opt]# chmod +x cfssl_linux-amd64 cfssljson_linux-amd64 [root@openshift-master1 /opt]# mv cfssl_linux-amd64 /usr/local/bin/cfssl [root@openshift-master1 /opt]# mv cfssljson_linux-amd64 /usr/local/bin/cfssljson   Etcd 证书生成所需配置文件如下:  [root@openshift-master1 /opt]# cat etcd-root-ca-csr.json { \u0026quot;key\u0026quot;: { \u0026quot;algo\u0026quot;: \u0026quot;rsa\u0026quot;, \u0026quot;size\u0026quot;: 4096 }, \u0026quot;names\u0026quot;: [ { \u0026quot;O\u0026quot;: \u0026quot;etcd\u0026quot;, \u0026quot;OU\u0026quot;: \u0026quot;etcd Security\u0026quot;, \u0026quot;L\u0026quot;: \u0026quot;Beijing\u0026quot;, \u0026quot;ST\u0026quot;: \u0026quot;Beijing\u0026quot;, \u0026quot;C\u0026quot;: \u0026quot;CN\u0026quot; } ], \u0026quot;CN\u0026quot;: \u0026quot;etcd-root-ca\u0026quot; } [root@openshift-master1 /opt]# cat etcd-gencert.json { \u0026quot;signing\u0026quot;: { \u0026quot;default\u0026quot;: { \u0026quot;usages\u0026quot;: [ \u0026quot;signing\u0026quot;, \u0026quot;key encipherment\u0026quot;, \u0026quot;server auth\u0026quot;, \u0026quot;client auth\u0026quot; ], \u0026quot;expiry\u0026quot;: \u0026quot;87600h\u0026quot; } } } [root@openshift-master1 /opt]# cat etcd-csr.json { \u0026quot;key\u0026quot;: { \u0026quot;algo\u0026quot;: \u0026quot;rsa\u0026quot;, \u0026quot;size\u0026quot;: 4096 }, \u0026quot;names\u0026quot;: [ { \u0026quot;O\u0026quot;: \u0026quot;etcd\u0026quot;, \u0026quot;OU\u0026quot;: \u0026quot;etcd Security\u0026quot;, \u0026quot;L\u0026quot;: \u0026quot;Beijing\u0026quot;, \u0026quot;ST\u0026quot;: \u0026quot;Beijing\u0026quot;, \u0026quot;C\u0026quot;: \u0026quot;CN\u0026quot; } ], \u0026quot;CN\u0026quot;: \u0026quot;etcd\u0026quot;, \u0026quot;hosts\u0026quot;: [ \u0026quot;127.0.0.1\u0026quot;, \u0026quot;localhost\u0026quot;, \u0026quot;192.168.124.22\u0026quot;, \u0026quot;192.168.124.23\u0026quot;, \u0026quot;192.168.124.24\u0026quot; ] }  注意: hosts 要将 etcd 集群的所在节点的 IP地址,主机名(FQDN),都要加入到此列表中\n 生成 Etcd 证书  [root@openshift-master1 /opt]# cfssl gencert --initca=true etcd-root-ca-csr.json | cfssljson --bare etcd-root-ca [root@openshift-master1 /opt]# cfssl gencert --ca etcd-root-ca.pem --ca-key etcd-root-ca-key.pem --config etcd-gencert.json etcd-csr.json | cfssljson --bare etcd #生成的证书列表如下 [root@openshift-master1 /opt] # ll 总用量 36 -rw-r--r-- 1 root root 2033 3月 27 18:09 etcd.csr -rw-r--r-- 1 root root 513 3月 27 18:09 etcd-csr.json -rw-r--r-- 1 root root 204 3月 27 18:08 etcd-gencert.json -rw------- 1 root root 3247 3月 27 18:09 etcd-key.pem -rw-r--r-- 1 root root 2415 3月 27 18:09 etcd.pem -rw-r--r-- 1 root root 1708 3月 27 18:09 etcd-root-ca.csr -rw-r--r-- 1 root root 232 3月 27 18:07 etcd-root-ca-csr.json -rw------- 1 root root 3243 3月 27 18:09 etcd-root-ca-key.pem -rw-r--r-- 1 root root 2078 3月 27 18:09 etcd-root-ca.pem  部署 ETCD 集群 第一个节点etcd0 安装  安装etcd，并将证书拷贝安装目录，赋权  [root@openshift-master1 /opt]# yum install etcd -y [root@openshift-master1 /opt]# cp *.pem /etc/etcd/ [root@openshift-master1 /opt]# chown -R etcd:etcd /etc/etcd/ [root@openshift-master1 /opt]# chmod -R 755 /etc/etcd/   配置内容  [root@openshift-master etcd]# cat /etc/etcd/etcd.conf #[Member] ETCD_DATA_DIR=\u0026quot;/var/lib/etcd/default.etcd\u0026quot; ETCD_LISTEN_PEER_URLS=\u0026quot;https://192.168.124.22:2380\u0026quot; ETCD_LISTEN_CLIENT_URLS=\u0026quot;https://192.168.124.22:2379,http://localhost:2379\u0026quot; ETCD_NAME=\u0026quot;etcd0\u0026quot; ETCD_HEARTBEAT_INTERVAL=500 ETCD_ELECTION_TIMEOUT=2500 #[Clustering] ETCD_INITIAL_ADVERTISE_PEER_URLS=\u0026quot;https://192.168.124.22:2380\u0026quot; ETCD_ADVERTISE_CLIENT_URLS=\u0026quot;https://192.168.124.22:2379\u0026quot; ETCD_INITIAL_CLUSTER=\u0026quot;etcd0=https://192.168.124.22:2380,etcd1=https://192.168.124.23:2380,etcd2=https://192.168.124.24:2380\u0026quot; ETCD_INITIAL_CLUSTER_TOKEN=\u0026quot;etcd-cluster\u0026quot; ETCD_INITIAL_CLUSTER_STATE=\u0026quot;new\u0026quot; #[Security] ETCD_CERT_FILE=\u0026quot;/etc/etcd/etcd.pem\u0026quot; ETCD_KEY_FILE=\u0026quot;/etc/etcd/etcd-key.pem\u0026quot; ETCD_CLIENT_CERT_AUTH=\u0026quot;true\u0026quot; ETCD_TRUSTED_CA_FILE=\u0026quot;/etc/etcd/etcd-root-ca.pem\u0026quot; ETCD_AUTO_TLS=\u0026quot;true\u0026quot; ETCD_PEER_CERT_FILE=\u0026quot;/etc/etcd/etcd.pem\u0026quot; ETCD_PEER_KEY_FILE=\u0026quot;/etc/etcd/etcd-key.pem\u0026quot; ETCD_PEER_CLIENT_CERT_AUTH=\u0026quot;true\u0026quot; ETCD_PEER_TRUSTED_CA_FILE=\u0026quot;/etc/etcd/etcd-root-ca.pem\u0026quot; ETCD_PEER_AUTO_TLS=\u0026quot;true\u0026quot;   启动服务  [root@openshift-master1 /opt]# systemctl enable etcd [root@openshift-master1 /opt]# systemctl start etcd  其他2个节点安装  安装 etcd 软件包  yum install etcd -y   将第一个节点的配置拷贝到其他2个节点  [root@openshift-master ~]# cd /etc/etcd/ [root@openshift-master etcd]# ll total 20 -rwxr-xr-x 1 etcd etcd 920 Apr 18 06:11 etcd.conf -rwxr-xr-x 1 etcd etcd 3243 Apr 18 06:07 etcd-key.pem -rwxr-xr-x 1 etcd etcd 2167 Apr 18 06:07 etcd.pem -rwxr-xr-x 1 etcd etcd 3247 Apr 18 06:07 etcd-root-ca-key.pem -rwxr-xr-x 1 etcd etcd 2078 Apr 18 06:07 etcd-root-ca.pem [root@openshift-master1 etcd]# scp * openshift-master2:/etc/etcd/ etcd.conf 100% 920 0.9KB/s 00:00 etcd-key.pem 100% 3243 3.2KB/s 00:00 etcd.pem 100% 2167 2.1KB/s 00:00 etcd-root-ca-key.pem 100% 3247 3.2KB/s 00:00 etcd-root-ca.pem 100% 2078 2.0KB/s 00:00   在其他2个节点上修改如下配置项,ip地址改成本节点的对应的IP地址  ETCD_LISTEN_PEER_URLS=\u0026quot;https://192.168.124.23:2380\u0026quot; ETCD_LISTEN_CLIENT_URLS=\u0026quot;https://192.168.124.23:2379,http://localhost:2379\u0026quot; #ETCD节点名称 按顺序增加即可 ETCD_NAME=\u0026quot;etcd1\u0026quot; ETCD_INITIAL_ADVERTISE_PEER_URLS=\u0026quot;https://192.168.124.23:2380\u0026quot; ETCD_ADVERTISE_CLIENT_URLS=\u0026quot;https://192.168.124.23:2379\u0026quot;   启动服务即可  验证(3个节点都安装配置完成后) [root@openshift-master etcd]# export ETCDCTL_API=3 [root@openshift-master etcd]# etcdctl member list 2da38978bc038ba1, started, etcd1, https://192.168.124.22:2380, https://192.168.124.22:2379 56e71904a9636fcf, started, etcd0, https://192.168.124.23:2380, https://192.168.124.23:2379 faf6915e4bb01350, started, etcd2, https://192.168.124.24:2380, https://192.168.124.24:2379 [root@openshift-master etcd]# etcdctl --cacert=/etc/etcd/etcd-root-ca.pem --cert=/etc/etcd/etcd.pem --key=/etc/etcd/etcd-key.pem --endpoints=https://192.168.124.22:2379,https://192.168.124.23:2379,https://192.168.124.24:2379 endpoint health https://192.168.124.22:2379 is healthy: successfully committed proposal: took = 3.852481ms https://192.168.124.23:2379 is healthy: successfully committed proposal: took = 4.035725ms https://192.168.124.24:2379 is healthy: successfully committed proposal: took = 1.489679ms  至此,etcd集群安装完成\n数据初始化 如果在安装过程中，可能需要重新初始化数据可以参考如下方法\n 导出API版本，这里使用3版本\nexport ETCDCTL_API=3  获取key\netcdctl get / --prefix --keys-only  删除 openshift.io 相关内容\netcdctl del --prefix=true /openshift.io  删除 kubernetes.io\netcdctl del --prefix=true /kubernetes.io  再次查看\netcdctl get / --prefix --keys-only   "
},
{
	"uri": "/openshift/install/master_install/",
	"title": "主服务安装",
	"tags": [],
	"description": "",
	"content": "    版本 日期 状态 修订人 摘要     V1.0 2018-04-17 创建 开源方案 初始版本    部署主机角色说明    主机角色 IP地址 负载域名     管理节点(Master) openshift-master1(192.168.124.22) openshift.ops.com   管理节点(Master) openshift-master2(192.168.124.23) openshift.ops.com   管理节点(Master) openshift-master3(192.168.124.24) openshift.ops.com    安装前基础环境检查 配置仓库源(如果自己建立本地源 直接跳过本步骤)  安装仓库源文件  yum install centos-release-openshift-origin.noarch   修改仓库配置 指向 V3.6版本(默认是指向最新的版本)  [root@openshift-master ~]# cat /etc/yum.repos.d/CentOS-OpenShift-Origin.repo [centos-openshift-origin] name=CentOS OpenShift Origin baseurl=http://mirrors.163.com/centos/7/paas/x86_64/openshift-origin36/ enabled=1 gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-SIG-PaaS 其他省略。。。。。。。。  主要是把 http://mirror.centos.org/centos/7/paas/x86_64/openshift-origin/ 修改为下面链接(使用163镜像) http://mirrors.163.com/centos/7/paas/x86_64/openshift-origin36/\n安装第一个master节点软件包  安装 origin-master  yum install origin-master -y   由于yum安装的master节点的证书不包含对外负载域名(openshift.ops.com),所以需要重新签发证书,并删除默认node配置  openshift start master --public-master='https://openshift.ops.com' --network-plugin='redhat/openshift-ovs-subnet' --write-config=/etc/origin/master rm -fr /etc/origin/node   查看证书生成的信息,DNS中会生成一个openshift.ops.com的域名  [root@openshift-master master]# openssl x509 -noout -text -in master.server.crt Certificate: Data: Version: 3 (0x2) Serial Number: 11 (0xb) Signature Algorithm: sha256WithRSAEncryption Issuer: CN=openshift-signer@1524139430 Validity Not Before: Apr 19 12:06:27 2018 GMT Not After : Apr 18 12:06:28 2020 GMT Subject: CN=127.0.0.1 Subject Public Key Info: Public Key Algorithm: rsaEncryption Public-Key: (2048 bit) Modulus: 00:b1:93:7c:57:d5:e1:c1:2c:59:1a:28:9e:b0:df: 38:cc:de:ab:d3:ab:6a:fa:97:3a:f2:79:80:26:0b: f0:92:7f:e3:e8:be:da:37:43:d0:f6:ce:d9:c1:e0: a5:cb:cf:af:04:bb:a4:bc:84:2c:a4:97:08:d4:c1: a5:d5:48:4f:3a:96:fb:2e:66:ad:6e:1f:d1:4a:8d: 21:c4:68:3d:f2:79:e2:3e:c5:e1:ee:78:2b:63:96: d7:fa:f2:e8:b4:58:45:1c:ba:6c:ca:0f:4b:b3:cf: 26:95:43:fe:fa:43:88:a4:48:c7:4e:07:83:66:eb: fe:48:78:f2:07:24:7c:a8:f4:6f:7b:80:5a:7e:7d: 0f:b2:87:46:5b:76:05:e2:d3:f0:58:87:69:64:5a: 17:91:70:6f:81:90:89:ac:65:57:cc:f2:67:8b:c7: 26:0d:79:b7:84:3f:58:ec:5c:d7:a2:85:17:36:e8: 62:86:6d:3d:21:43:38:cf:1c:2c:c4:c9:3d:6c:b4: da:c3:0c:5e:ca:3f:74:ff:b7:39:1e:fb:63:bf:47: 66:54:54:8f:88:c3:8f:ba:a5:dd:70:ec:53:6a:ce: 49:48:77:1a:10:cc:81:bb:85:a4:55:b7:07:e9:fa: 7c:67:38:40:35:1c:bf:cf:ee:45:79:19:6b:69:45: 3d:0b Exponent: 65537 (0x10001) X509v3 extensions: X509v3 Key Usage: critical Digital Signature, Key Encipherment X509v3 Extended Key Usage: TLS Web Server Authentication X509v3 Basic Constraints: critical CA:FALSE X509v3 Subject Alternative Name: DNS:kubernetes, DNS:kubernetes.default, DNS:kubernetes.default.svc, DNS:kubernetes.default.svc.cluster.local, DNS:localhost, DNS:openshift, DNS:openshift.default, DNS:openshift.default.svc, DNS:openshift.default.svc.cluster.local, DNS:openshift.ops.com, DNS:127.0.0.1, DNS:172.30.0.1, DNS:192.168.124.22, IP Address:127.0.0.1, IP Address:172.30.0.1, IP Address:192.168.124.22 Signature Algorithm: sha256WithRSAEncryption d5:8b:11:66:64:0e:cc:b9:36:85:15:1f:75:02:d1:9b:5c:32: b5:af:1e:d9:38:85:e0:95:77:d7:5d:42:dd:e9:40:07:c8:d2: ae:4b:99:db:8f:61:49:e7:3b:37:4b:22:cc:0b:07:5d:6a:39: ce:82:e8:00:38:4e:af:14:1b:9c:78:6a:2e:58:b8:44:c0:62: 96:18:7d:58:2c:9c:db:87:e3:47:20:61:97:7f:ae:3f:74:c5: 4a:cc:88:e6:6b:1b:4c:b4:16:6d:66:99:4a:7f:bc:51:ec:b4: 17:66:56:ab:d5:16:0f:a8:2b:8b:5c:dc:91:e1:bc:3b:99:41: 5b:ad:cb:f0:52:20:23:93:46:44:de:cf:fe:70:27:ec:8d:eb: 65:23:84:5d:cb:75:18:31:19:d9:0d:8c:43:0b:6f:c7:97:1e: 02:41:d9:07:93:bb:b0:dc:53:08:54:0e:48:cc:1c:60:4d:87: c2:a8:be:56:55:af:53:62:21:29:2b:43:eb:38:45:f9:11:52: b6:d8:56:77:3d:a0:34:1c:69:3b:e1:3d:f9:85:46:f9:60:b9: 2e:b4:b2:e2:54:a7:20:7a:a3:50:de:38:ad:4b:31:e3:45:2c: 45:3a:b6:8c:a3:5f:80:47:97:f9:e8:2f:e6:b8:2d:11:55:3d: 0a:6a:fc:18   修改master etcd配置,使用前面配置好的etcd集群  修改前\n[root@openshift-master master]# cat /etc/origin/master/master-config.yaml .....省略..... etcdClientInfo: ca: ca.crt certFile: master.etcd-client.crt keyFile: master.etcd-client.key urls: - https://192.168.124.22:4001 etcdConfig: address: 192.168.124.22:4001 peerAddress: 192.168.124.22:7001 peerServingInfo: bindAddress: 0.0.0.0:7001 bindNetwork: tcp4 certFile: etcd.server.crt clientCA: ca.crt keyFile: etcd.server.key namedCertificates: null servingInfo: bindAddress: 0.0.0.0:4001 bindNetwork: tcp4 certFile: etcd.server.crt clientCA: ca.crt keyFile: etcd.server.key namedCertificates: null storageDirectory: /etc/origin/openshift.local.etcd etcdStorageConfig: kubernetesStoragePrefix: kubernetes.io kubernetesStorageVersion: v1 openShiftStoragePrefix: openshift.io openShiftStorageVersion: v1 .....省略.....  修改后\n[root@openshift-master master]# cat /etc/origin/master/master-config.yaml .....省略..... etcdClientInfo: ca: master.etcd-ca.crt certFile: master.etcd-client.crt keyFile: master.etcd-client.key urls: - https://192.168.124.22:2379 - https://192.168.124.23:2379 - https://192.168.124.24:2379 etcdStorageConfig: kubernetesStoragePrefix: kubernetes.io kubernetesStorageVersion: v1 openShiftStoragePrefix: openshift.io openShiftStorageVersion: v1 .....省略.....   openshift配置与etcd的证书对应关系     openshift证书名 etcd证书名     master.etcd-ca.crt etcd-root-ca.pem   master.etcd-client.crt etcd.pem   master.etcd-client.key etcd-key.pem     拷贝相关证书到master目录  [root@openshift-master master]# cat /etc/origin/master/master-config.yaml ^C [root@openshift-master master]# cp /etc/etcd/etcd-root-ca.pem /etc/origin/master/master.etcd-ca.crt [root@openshift-master master]# cp /etc/etcd/etcd.pem /etc/origin/master/master.etcd-client.crt cp: overwrite ‘/etc/origin/master/master.etcd-client.crt’? y [root@openshift-master master]# cp /etc/etcd/etcd-key.pem /etc/origin/master/master.etcd-client.key cp: overwrite ‘/etc/origin/master/master.etcd-client.key’? y   启动master  systemctl enable origin-master.service systemctl start origin-master.service  权限登录配置 超级admin用户登陆配置说明(只能命令行登陆)  admin 用户登陆使用密钥文件  /etc/origin/master/admin.kubeconfig   管理员登陆 使用证书密钥进行管理(当前用户是root)  [root@openshift-master ~]# mkdir -p /root/.kube [root@openshift-master ~]# cp /etc/origin/master/admin.kubeconfig /root/.kube/config [root@openshift-master ~]# oc login -u system:admin Logged into \u0026quot;https://192.168.124.22:8443\u0026quot; as \u0026quot;system:admin\u0026quot; using existing credentials. You have access to the following projects and can switch between them with 'oc project \u0026lt;projectname\u0026gt;': * default kube-public kube-system openshift openshift-infra Using project \u0026quot;default\u0026quot;.   执行 如下命令可以看到当前登录用户  [root@openshift-master ~]# oc whoami system:admin  WEBUI 登陆用户配置  安装完默认是任意密码登陆，这里配置htpasswd方式进行认证  修改前\n provider: apiVersion: v1 kind: AllowAllPasswordIdentityProvider  修改后\n provider: apiVersion: v1 kind: HTPasswdPasswordIdentityProvider file: /etc/origin/master/htpasswd   安装htpasswd  [root@openshift-master master]# yum install httpd-tools -y   添加ops账户  [root@openshift-master master]# htpasswd -c /etc/origin/master/htpasswd ops New password: Re-type new password: Adding password for user ops   将ops用户加入openshift-infra 和 default 项目，并赋予admin权限  [root@openshift-master master]# oc adm policy add-role-to-user admin ops -n openshift-infra role \u0026quot;admin\u0026quot; added: \u0026quot;ops\u0026quot; [root@openshift-master master]# oc adm policy add-role-to-user admin ops -n default role \u0026quot;admin\u0026quot; added: \u0026quot;ops\u0026quot;   重启master 节点  systemctl daemon-reload systemctl restart origin-master  至此 第一个master节点安装部署完成\n其他2个master节点安装  参考第一个节点,配置仓库,安装 origin-master 软件包\n 将第一个master节点的 ca配置和相关配置文件拷贝到其他master节点上\nscp ca.* master.etcd-* htpasswd openshift-master2:/etc/origin/master  在其他2个节点重新生成配置\nopenshift start master --public-master='https://openshift.ops.com' --network-plugin='redhat/openshift-ovs-subnet' --write-config=/etc/origin/master  参考上文设置 超级admin用户登陆配置\n 启动master节点即可\n 检查日志,无错误,安装完成\n  "
},
{
	"uri": "/openshift/install/haproxy_install/",
	"title": "Haproxy安装",
	"tags": [],
	"description": "",
	"content": "    版本 日期 状态 修订人 摘要     V1.0 2018-04-17 创建 开源方案 初始版本    部署主机说明    主机角色 IP地址 操作系统 摘要 域名     管理节点(Master) openshift-master1(192.168.124.22) CentOS Linux release 7.3.1611 (Core) x86_64 master + etcd + haproxy openshift.ops.com    安装haproxy [root@openshift-master1 /root]# yum install haproxy -y   修改配置文件  [root@openshift-master1 /root]# vim /etc/haproxy/haproxy.cfg # Global settings #--------------------------------------------------------------------- global maxconn 20000 log /dev/log local0 info chroot /var/lib/haproxy pidfile /var/run/haproxy.pid user haproxy group haproxy daemon # turn on stats unix socket stats socket /var/lib/haproxy/stats #--------------------------------------------------------------------- # common defaults that all the 'listen' and 'backend' sections will # use if not designated in their block #--------------------------------------------------------------------- defaults mode http log global option httplog option dontlognull # option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 300s timeout server 300s timeout http-keep-alive 10s timeout check 10s maxconn 20000 listen stats :9000 mode http stats enable stats uri / frontend atomic-openshift-api bind *:443 default_backend atomic-openshift-api mode tcp option tcplog backend atomic-openshift-api balance source mode tcp server master0 192.168.124.22:8443 check server master1 192.168.124.23:8443 check server master2 192.168.124.24:8443 check  注意: 确保域名 openshift.ops.com 指向Haproxy (如没配置dns,请在各计算节点做hosts绑定)\n启动服务 systemctl enable haproxy systemctl start haproxy  "
},
{
	"uri": "/openshift/install/node_install/",
	"title": "计算节点安装",
	"tags": [],
	"description": "",
	"content": "    版本 日期 状态 修订人 摘要     V1.0 2018-04-17 创建 开源方案 初始版本    部署主机角色说明    主机角色 IP地址 域名     基础设施节点(Node) openshift-node1（192.168.124.30） lb.openshift.ops.com   计算节点(Node) openshift-node2（192.168.124.46） 无对外域名    安装node节点(计算节点)  设置仓库源（参考主服务安装）\n 安装docker\nyum install docker -y  配置docker\n  [root@openshift-node1 node]# cat /etc/docker/daemon.json { \u0026quot;registry-mirrors\u0026quot;: [\u0026quot;http://ef017c13.m.daocloud.io\u0026quot;], \u0026quot;insecure-registries\u0026quot;: [ \u0026quot;172.30.0.0/16\u0026quot;,\u0026quot;172.30.102.47:5000\u0026quot;,\u0026quot;openshift-master1:5000\u0026quot;] }  注意: insecure-registries 代表docker 使用http 而不使用https(默认是https方式)访问 docker镜像仓库\n 启动docker  systemctl enable docker systemctl start docker   安装 node 软件包\nyum install origin-node origin-sdn-ovs -y  生成 node 配置文件(默认是没有的) 将master的 ca配置文件 拷贝到 node 节点 (master节点上操作)\ncd /etc/origin/master/ scp ca.crt ca.key ca.serial.txt openshift-node1:/etc/origin/node/  在node节点上 生成配置(node节点上操作)\n  oc adm create-node-config \\ --node-dir=/etc/origin/node \\ --node=openshift-node1 \\ --hostnames=openshift-node1,192.168.124.30 \\ --certificate-authority=\u0026quot;/etc/origin/node/ca.crt\u0026quot; \\ --signer-cert=\u0026quot;/etc/origin/node/ca.crt\u0026quot; \\ --signer-key=\u0026quot;/etc/origin/node/ca.key\u0026quot; \\ --signer-serial=\u0026quot;/etc/origin/node/ca.serial.txt\u0026quot; \\ --node-client-certificate-authority=\u0026quot;/etc/origin/node/ca.crt\u0026quot; \\ --network-plugin=\u0026quot;redhat/openshift-ovs-subnet\u0026quot; \\ --dns-ip='172.30.0.1' \\ --master='https://openshift.ops.com'  注意: 如下设置要改成对应计算节点的信息\n--node=openshift-node1 \\ --hostnames=openshift-node1,192.168.124.30 \\   启动node节点(确保openshhift.ops.com能够解析或者hosts绑定)  systemctl enable origin-node systemctl start origin-node   检查日志和到服务端确认node注册成功  [root@openshift-master master]# oc get node NAME STATUS AGE VERSION openshift-node1 Ready 44s v1.6.1+5115d708d7 [root@openshift-master master]# oc get hostsubnet NAME HOST HOST IP SUBNET openshift-node1 openshift-node1 192.168.124.30 10.128.0.0/23  "
},
{
	"uri": "/openshift/install/router_registry_install/",
	"title": "Router And Registry安装",
	"tags": [],
	"description": "",
	"content": "    版本 日期 状态 修订人 摘要     V1.0 2018-04-17 创建 开源方案 初始版本    部署主机角色说明    主机角色 IP地址 节点标签 域名     基础设施节点(Node) openshift-node1（192.168.124.30) zone=ops lb.openshift.ops.com    说明:\nrouter 组件是用户访问的入口，域名都需要指向Router组件所在运行的计算节点上\nregistry组件是openshift集群内部使用的docker仓库,主要存放源代码打包生成的镜像\n部署 Router 组件  给Node节点打标签  [root@openshift-master master]# oc label node openshift-node1 zone=ops node \u0026quot;openshift-node1\u0026quot; labeled [root@openshift-master master]# oc get node --show-labels NAME STATUS AGE VERSION LABELS openshift-node1 Ready 3h v1.6.1+5115d708d7 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=openshift-node1,zone=ops openshift-node2 Ready 31m v1.6.1+5115d708d7 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=openshift-node2  通过对Node节点打标签，在部署组件的时候，可以指定部署到特定节点上\n 建立一个 service account 关联router 并赋予权限  [root@openshift-master ~]# oc project default [root@openshift-master ~]# oadm policy add-scc-to-user privileged system:serviceaccount:default:router [root@openshift-master ~]# oadm policy add-cluster-role-to-user cluster-reader system:serviceaccount:default:router cluster role \u0026quot;cluster-reader\u0026quot; added: \u0026quot;system:serviceaccount:default:router\u0026quot;   创建一个名为 router01 的实例，在指定的计算节点上  [root@openshift-master ~]# oadm router router01 --replicas=1 --service-account=router --selector='zone=ops' info: password for stats user admin has been set to iC3sKtFY5k --\u0026gt; Creating router router01 ... serviceaccount \u0026quot;router\u0026quot; created clusterrolebinding \u0026quot;router-router01-role\u0026quot; created deploymentconfig \u0026quot;router01\u0026quot; created service \u0026quot;router01\u0026quot; created --\u0026gt; Success 查看状态 [root@openshift-master ~]# oc get pod -n default NAME READY STATUS RESTARTS AGE router01-1-deploy 0/1 ContainerCreating 0 1m 正在下载docker images 过几分钟再看(取决于下载速度) [root@openshift-master ~]# oc get pod -n default NAME READY STATUS RESTARTS AGE router01-1-hvc1j 1/1 Running 0 1m  部署registry [root@openshift-master ~]# oadm registry --config=/etc/origin/master/admin.kubeconfig --service-account=registry --selector='zone=ops' --\u0026gt; Creating registry registry ... serviceaccount \u0026quot;registry\u0026quot; created clusterrolebinding \u0026quot;registry-registry-role\u0026quot; created deploymentconfig \u0026quot;docker-registry\u0026quot; created service \u0026quot;docker-registry\u0026quot; created --\u0026gt; Success [root@openshift-master ~]# oc get pod NAME READY STATUS RESTARTS AGE docker-registry-1-deploy 0/1 ContainerCreating 0 3s router01-1-hvc1j 1/1 Running 0 14h [root@openshift-master ~]# oc get pod NAME READY STATUS RESTARTS AGE docker-registry-1-k5zq1 1/1 Running 0 3m router01-1-hvc1j 1/1 Running 0 14h  查看各个SERVICE的内部集群地址 [root@openshift-master ~]# oc get svc NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE docker-registry 172.30.111.126 \u0026lt;none\u0026gt; 5000/TCP 9m kubernetes 172.30.0.1 \u0026lt;none\u0026gt; 443/TCP,53/UDP,53/TCP 22h router01 172.30.121.139 \u0026lt;none\u0026gt; 80/TCP,443/TCP,1936/TCP 15h  注意: 172.30.0.0/16 这个段是 cluster ip,如果容器出现问题或者迁移，这个 cluster ip 是不会改变的\n"
},
{
	"uri": "/openshift/install/metric_install/",
	"title": "度量系统安装",
	"tags": [],
	"description": "",
	"content": "    版本 日期 状态 修订人 摘要     V1.0 2018-04-17 创建 开源方案 初始版本    度量采集服务架构图 使用ansible进行部署  安装openshift ansible 软件包\nyum install ansible.noarch java-1.8.0-openjdk-headless -y  clone openshift-ansible 项目\n  cd /opt git clone https://github.com/openshift/openshift-ansible.git git checkout origin/release-3.6   配置metric_hosts部署文件  [root@openshift-master ~]# cat /etc/ansible/metric_hosts [OSEv3:children] masters nodes [OSEv3:vars] ansible_ssh_user=root openshift_deployment_type=origin openshift_metrics_install_metrics=True openshift_metrics_image_prefix=openshift/origin- #拉取的镜像版本 openshift_metrics_image_version=v3.6.1 openshift_metrics_resolution=10s #metrics_hawkular服务对外的域名(指向router节点) openshift_metrics_hawkular_hostname=metrics.ops.com #master的ip openshift_metrics_master_url=https://openshift.ops.com # cassandra 使用临时存储 openshift_metrics_cassandra_storage_type=emptydir [masters] openshift-master [nodes] openshift-node1 openshift-node2   执行ansible-playbook(第一次执行可能会失败，如果失败就再执行一次)  ansible-playbook -i /etc/ansible/metric_hosts /opt/openshift-ansible/playbooks/byo/openshift-cluster/openshift-metrics.yml   执行结果，部署的快慢根据由拉取镜像的速度决定，成功的结果如下(READY都是1/1表示成功)\n# oc get pod -n openshift-infra NAME READY STATUS RESTARTS AGE hawkular-cassandra-1-m1p40 1/1 Running 0 4m hawkular-metrics-lf9hb 1/1 Running 0 4m heapster-1c2h0 1/1 Running 0 4m  检查master-config.yaml配置\ncat /etc/origin/master/master-config.yaml ...... masterPublicURL: https://openshift.ops.com:443 metricsPublicURL: https://metrics.ops.com/hawkular/metrics #确认此选项配置 publicURL: https://openshift.ops.com:443/console/ ....  重启master\nsystemct restart origin-master   成功后查看监控信息 "
},
{
	"uri": "/openshift/install/efk_install/",
	"title": "EFK日志系统安装",
	"tags": [],
	"description": "",
	"content": "    版本 日期 状态 修订人 摘要     V1.0 2018-04-17 创建 开源方案 初始版本    部署日志采集服务  因为每个节点都需要采集日志，所以新建的logging项目选择的标签为空。\n[root@hz01-prod-ops-openshiftmaster-01 /]# oc adm new-project logging --node-selector=\u0026quot;\u0026quot;  修改ansible配置文件\n  cat /etc/ansible/log_hosts [OSEv3:children] masters nodes [OSEv3:vars] ansible_ssh_user=root openshift_deployment_type=origin openshift_logging_install_logging=True openshift_logging_image_version=v3.6.1 openshift_logging_kibana_hostname=kibana.ops.com #The URL for the Kubernetes master, this does not need to be public facing but should be accessible from within the cluster. #default is https://kubernetes.default.svc.cluster.local #openshift_logging_master_url=https://openshift.ops.com #The public facing URL for the Kubernetes master. This is used for Authentication redirection by the Kibana proxy. openshift_logging_master_public_url=https://openshift.ops.com openshift_logging_es_memory_limit=1G [masters] openshift-master [nodes] openshift-node1 openshift-node2   执行安装日志采集服务\nansible-playbook -i /etc/ansible/log_hosts /opt/openshift-ansible/playbooks/byo/openshift-cluster/openshift-logging.yml  确认部署是否成功\n[root@hz01-prod-ops-openshiftmaster-01 /root] # oc get pod NAME READY STATUS RESTARTS AGE logging-curator-1-01khs 1/1 Running 0 1d logging-es-data-master-f9r7g76t-1-bpvkq 1/1 Running 0 1d logging-fluentd-05cr8 1/1 Running 0 1d logging-fluentd-wc8ht 1/1 Running 0 1d logging-kibana-1-h4rl1 2/2 Running 0 1d   至此集中日志功能部署完成\n可能碰到的问题  log-es 集群启动会出现如下错误(通过 oc logs 查看)  [2017-11-01 15:10:02,491][INFO ][container.run ] Begin Elasticsearch startup script -- | [2017-11-01 15:10:02,498][INFO ][container.run ] Comparing the specified RAM to the maximum recommended for Elasticsearch... | [2017-11-01 15:10:02,499][INFO ][container.run ] Inspecting the maximum RAM available... | [2017-11-01 15:10:02,503][INFO ][container.run ] ES_HEAP_SIZE: '4096m' | [2017-11-01 15:10:02,506][INFO ][container.run ] Setting heap dump location /elasticsearch/persistent/heapdump.hprof | [2017-11-01 15:10:02,509][INFO ][container.run ] Checking if Elasticsearch is ready on https://localhost:9200 | Exception in thread \u0026quot;main\u0026quot; java.lang.IllegalArgumentException: Unknown Discovery type [kubernetes] | at org.elasticsearch.discovery.DiscoveryModule.configure(DiscoveryModule.java:100) | at \u0026lt;\u0026lt;\u0026lt;guice\u0026gt;\u0026gt;\u0026gt; | at org.elasticsearch.node.Node.\u0026lt;init\u0026gt;(Node.java:213) | at org.elasticsearch.node.Node.\u0026lt;init\u0026gt;(Node.java:140) | at org.elasticsearch.node.NodeBuilder.build(NodeBuilder.java:143) | at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:194) | at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:286) | at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:45) | Refer to the log for complete error details.  这个有2中解决方法\n 将ansible的host配置文中中 openshift_logging_image_version=v3.6.1 改为 openshift_logging_image_version=latest\n 修改已有的 dc(部署配置) oc edit dc/logging-es-data-master-we71py7f\n  将如下行\nimage: docker.io/openshift/origin-logging-elasticsearch:latest  变更成\nimage: docker.io/openshift/origin-logging-elasticsearch:v3.6  原因是请查看 https://hub.docker.com/r/openshift/origin-logging-elasticsearch/tags/ v3.6 与 v3.6.1 相比,从更新时间上来说 v3.6 属于最新版本\n"
},
{
	"uri": "/openshift/install/",
	"title": "集群安装",
	"tags": [],
	"description": "",
	"content": " 第一章 生产集群安装 本章主要讲述 Openshift Origin 安装配置步骤\n"
},
{
	"uri": "/openshift/application/",
	"title": "应用部署",
	"tags": [],
	"description": "",
	"content": " 第二章 应用部署 本章主要讲述 openshift origin 平台上应用部署相关配置实践\n"
},
{
	"uri": "/openshift/monitor/",
	"title": "平台监控",
	"tags": [],
	"description": "",
	"content": " 第三章 平台监控 本章主要讲述 openshift origin 集群监控相关配置实践\n"
},
{
	"uri": "/openshift/appcenter/",
	"title": "组件中心",
	"tags": [],
	"description": "",
	"content": " 第四章 组件中心 本章主要讲述如何构建自己企业内部的组件或者应用中心的相关配置实践\n"
},
{
	"uri": "/openshift/security/",
	"title": "平台安全",
	"tags": [],
	"description": "",
	"content": " 第五章 平台安全 本章主要讲述Openshift Origin 平台信息安全配置等实践\n"
},
{
	"uri": "/openshift/devops/",
	"title": "开发运维",
	"tags": [],
	"description": "",
	"content": " 第六章 DevOps 本章主要主要讲述DevOps在Openshift Origin 平台上的相关实践\n"
},
{
	"uri": "/openshift/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/openshift/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/openshift/",
	"title": "红帽 OpenShift",
	"tags": [],
	"description": "",
	"content": " 红帽 OpenShift 红帽® OpenShift 是一款容器应用平台，它将 Docker 和 Kubernetes 技术带入企业。\n无论您采用何种应用架构，OpenShift 都能让您在任意架构中（公共或私有云中）轻松、快速实现应用的构建、开发和部署。\n无论是在企业内部，公共云，或是托管环境中，您都能凭借这一备受业务青睐的平台，快速您的最新创意推向市场，从而在激烈的市场竞争中脱颖而出。\n本套文档涉及到的版本    版本 类型 备注     CentOS Linux release 7.3.1611 (Core) 操作系统 使用centos   Openshift Origin v3.6.1 容器云 使用开源版本    问题反馈 在看文档过程中，有任何问题，请到这里留言反馈，谢谢。\n我们会在第一时间响应回复\n openshift origin 使用客户列表 如果您在真实的生产工作中，使用了openshift origin, 请反馈给我们,也能看出在国内的使用情况,请到这里推荐给我们\nOpenshift 功能和优势  企业级 Kubernetes\n红帽 OpenShift 作为一个功能全面容器应用平台，其自身具备 Docker 和 Kubernetes 等最新技术，是一款功能强大的容器集群管理和编排系统。 该平台和红帽企业 Linux系统一同为企业提供坚实技术基础。 OpenShift 集成了企业所需的多种架构、流程、平台及服务，可为开发和运营团队同时提供强大支持。\n 有状态和无状态的应用\n红帽 OpenShift 可运行和支持有状态和无状态的应用。因此，您无需完全重构您的企业应用，即可充分利用容器技术。\n 实现应用现代化\nOpenShift 与红帽 JBoss 中间件相结合后，可以实现多种综合性云原生服务，包括开发人员工具、整合、业务自动化、数据管理等。因而，有助您更加快速、智能、灵活地开发应用，克服使用微服务构建分布式系统的挑战。\n 构建更出色、更强大的混合云\n就像红帽企业 Linux，这一用于构建众多公共、私有云环境的基础平台一样，您可以在任意位置部署 OpenShift 和获得相应支持。这些云环境包括 Amazon Web Services、Azure、Google 云平台、VMware 等等。依托 OpenShift，您可以在这些公共云和私有云上，提供单个容器应用平台。另外，借助在 Microsoft Azure 上运行的红帽 OpenShift 容器平台，您可以构建、部署和管理容器化服务和应用。\n 拥抱 DevOps\nOpenShift 为开发和运营团队提供了一个通用平台和一整套开发和管理工具。这使得两个团队能够步调一致，保持持续、协调化的应用开发和维护流程。通过此方法，您可以消除耗时缓慢的业务流程和手动操作，根据业务需求灵活开展运营。\n  "
}]